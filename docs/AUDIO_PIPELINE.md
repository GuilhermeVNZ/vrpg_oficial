# VRPG ‚Äî Arquitetura de Voz Local (Pipeline de 3 Agentes: Qwen-1.5B ‚Üí Qwen-14B ‚Üí XTTS)

O objetivo do pipeline sonoro do VRPG √© permitir que o jogador experimente uma mesa real, narrada por um Mestre IA com vozes de NPCs, acompanhado por jogadores IA com personalidade, m√∫sica din√¢mica, e efeitos sonoros emergentes, sem rupturas.

---

## üî• Princ√≠pio Central

**O LLM n√£o √© a voz. A voz n√£o √© o LLM. A emo√ß√£o n√£o √© o texto.**

Cada camada tem uma responsabilidade √∫nica:

- **Qwen-1.5B cria rea√ß√£o humana imediata (prel√∫dio).**
- **Qwen-14B cria a inten√ß√£o narrativa completa e a fala.**
- **XTTS (Coqui XTTS v2) sintetiza o texto diretamente com a voz do personagem usando embeddings personalizados.**

Isso elimina lat√™ncia, evita instabilidade emocional do TTS end-to-end e garante consist√™ncia vocal entre sess√µes.

**Regra de Ouro**: O 1.5B sempre responde antes do 14B para evitar sil√™ncio cognitivo.

---

## 1. Arquitetura Geral de √Åudio

O √°udio do VRPG √© dividido em 4 camadas independentes:

1. **Voz mestre** (Narrador + NPCs)
2. **Voz jogadores IA**
3. **M√∫sica procedural**
4. **Sound FX** (ambiente / a√ß√µes / combate)

Cada camada possui:

- modelo local dedicado
- buffer PCM
- mixagem din√¢mica
- prioridade temporal

**A voz sempre vence a m√∫sica.**  
Efeitos sonoros n√£o interrompem fala.

---

## 2. Objetivo Principal: Zero API

‚ùå **Nada de ElevenLabs ou TTS web.**

Mesmo se a qualidade "pare√ßa melhor", a lat√™ncia destr√≥i a imers√£o:

```
whisper ‚Üí texto ‚Üí API ‚Üí resposta ‚Üí download ‚Üí playback
= 1500‚Äì2500ms + jitter
‚Üí ruim em RPG narrativo.
```

‚úîÔ∏è **IA local com arquitetura em 3 camadas:**

1. **Qwen 2.5 1.5B (q4_K_M)** ‚Üí rea√ß√£o humana imediata, prel√∫dio emocional (< 1.2s) ‚Üí **Perfil FAST TTS** (‚â§ 0.8s lat√™ncia)
2. **Qwen 2.5 14B (q4_K_M)** ‚Üí racioc√≠nio, contexto, inten√ß√£o narrativa completa, dire√ß√£o emocional (< 6s) ‚Üí **Perfil CINEMATIC TTS** (1.5-3s lat√™ncia)
3. **XTTS v2 (Coqui)** ‚Üí s√≠ntese direta com voz do personagem usando embeddings personalizados (velocidade, inteligibilidade, multi-idioma, identidade vocal) ‚Üí **Streaming real com FIFO** (n√£o batch)

---

## 3. QWEN 1.5B ‚Äî "O reflexo humano"

### Fun√ß√£o:

- gerar **rea√ß√£o emocional imediata** (1-2 frases, 15-45 palavras)
- preencher sil√™ncio cognitivo enquanto o 14B prepara resposta completa
- simular a "respira√ß√£o" de um mestre humano experiente
- **NUNCA** narrar resultados, aplicar regras, ou resolver a√ß√µes

**Ver especifica√ß√£o completa em [QWEN_1_5B_SPEC.md](QWEN_1_5B_SPEC.md)**

---

## 4. QWEN 2.5 14B ‚Äî "O c√©rebro"

### Fun√ß√£o:

- gerar **fala dram√°tica** (n√£o s√≥ respostas)
- interpretar o estado da cena e do turno
- decidir **quem est√° falando**
- gerar **dire√ß√£o de atua√ß√£o** para XTTS (via Voice INTENTs)
- modelar as inten√ß√µes internas:
  - medo, arrog√¢ncia, calma, sarcasmo, f√∫ria
- contextualizar com lore, regras, passado e decis√µes anteriores
- **TTS**: Usa **Perfil CINEMATIC** (1.5-3s lat√™ncia, primeiro chunk de 100 chars)

### Exemplo de sa√≠da ideal de Qwen:

```xml
<VOICE actor="NPC_Cultist" emotion="rage" style="crackled">
"TRAIDORES! O Deus das Cinzas os consumir√°!!"
</VOICE>
```

**Qwen nunca gera √°udio.**  
**Qwen gera texto + metadados emocionais.**

---

## 5. XTTS ‚Äî "A voz do personagem"

O XTTS (Coqui XTTS v2) √© o sintetizador TTS ultra-r√°pido, local, de baixa lat√™ncia que gera √°udio diretamente com a voz do personagem.

**O XTTS √© a voz completa do personagem, n√£o apenas s√≠ntese neutra.**

### Fun√ß√µes do XTTS:

- converter a fala do Qwen ‚Üí √°udio com voz do personagem
- usar embeddings personalizados (reference WAV) para cada personagem
- output consistente e natural
- 100% offline
- 50‚Äì200ms/infer√™ncia (dependendo do hardware e GPU)
- Multi-idioma nativo
- Suporte GPU para lat√™ncia reduzida
- **√Åudio RAW (sem processamento) = melhor qualidade**

### Streaming Real-Time Cinematogr√°fico

O XTTS agora suporta **streaming real-time cinematogr√°fico** com perfis de performance adaptativos:

#### Perfis de Performance TTS

O sistema implementa dois perfis distintos para otimizar lat√™ncia:

**Perfil FAST (Qwen 1.5B)**:
- **Primeiro chunk**: 30 caracteres m√°ximo (~0.7-1.0s de fala)
- **Pr√≥ximos chunks**: 90 caracteres m√°ximo (~2-3s de fala)
- **Sample rate**: 16 kHz (mono)
- **Precis√£o**: FP16 (half precision)
- **Audio blocks**: 50ms (800 samples @ 16 kHz)
- **Pre-buffer inicial**: 240ms
- **Target lat√™ncia**: ‚â§ 0.8s (ideal 0.5-0.7s)
- **Uso**: Respostas r√°pidas do Qwen 1.5B (prel√∫dio emocional)

**Perfil CINEMATIC (Qwen 14B)**:
- **Primeiro chunk**: 100 caracteres m√°ximo (~3s de fala)
- **Pr√≥ximos chunks**: 150 caracteres m√°ximo (~4-5s de fala)
- **Sample rate**: 24 kHz (mono)
- **Precis√£o**: FP16 (half precision)
- **Audio blocks**: 60-80ms (1440-1920 samples @ 24 kHz)
- **Pre-buffer inicial**: 500ms
- **Target lat√™ncia**: 1.5-3s
- **Uso**: Narrativas completas do Qwen 14B

#### Streaming Real-Time

- **Chunking adaptativo**: Primeiro chunk min√∫sculo (FAST) ou moderado (CINEMATIC)
- **FIFO streaming**: Blocos de 50-80ms empurrados imediatamente para fila
- **Pre-buffering adaptativo**: 240ms (FAST) ou 500ms (CINEMATIC) antes de iniciar playback
- **Paraleliza√ß√£o adaptativa**: 2-3 CUDA streams (High-End) ou sequencial (Modest)
- **FIFO buffer**: Thread-safe, zero-gap playback
- **Thread dedicada**: I/O de √°udio isolada (n√£o compartilha com UI/modelo)
- **Lat√™ncia inicial**: ‚â§ 0.8s (FAST) ou 1.5-3s (CINEMATIC)
- **Continuidade**: Zero gaps entre chunks ap√≥s in√≠cio

### Controle Adaptativo de GPU

O sistema detecta automaticamente o hardware e adapta configura√ß√£o:

- **High-End** (RTX 5090): 2-3 streams paralelos, 2.5s pre-buffer, 80-95% GPU
- **Mid-Range** (RTX 3070): 1-2 streams, 1.75s pre-buffer, 60-80% GPU
- **Modest** (RTX 3050): 1 stream sequencial, 1.25s pre-buffer, 40-60% GPU
- **Low-End** (< 4GB): 0-1 stream, 0.75s pre-buffer, 30-50% GPU

**Performance mantida em todos os tiers**: < 5s lat√™ncia inicial, zero gaps, sistema responsivo.

### Otimiza√ß√µes de √Åudio

- **Sample rate**: 16-24 kHz (suficiente para voz, N√ÉO 48 kHz)
- **Channels**: Mono (1 canal, N√ÉO est√©reo - 50% menos banda)
- **Buffer size**: 256-512 frames (baixa lat√™ncia, N√ÉO 2048/4096)
- **Formato I/O**: int16 PCM (eficiente, compat√≠vel Opus, N√ÉO float64)
- **Formato interno**: Float32 (infer√™ncia XTTS, preserva qualidade)

### Por que XTTS com Embeddings?

Porque:

- **Qualidade superior**: √Åudio RAW do XTTS √© infinitamente melhor que qualquer processamento
- **Lat√™ncia baixa**: S√≠ntese direta sem camadas adicionais
- **Escal√°vel**: Um embedding por personagem (f√°cil de criar e gerenciar)
- **Natural**: Voz preserva caracter√≠sticas naturais do personagem
- **Sem artefatos**: Processamento adicional degrada qualidade

**Em VRPG voc√™ quer:**

Texto com emo√ß√£o ‚Üí XTTS com embedding do personagem ‚Üí √Åudio final perfeito.

### Embeddings XTTS

Cada personagem tem seu pr√≥prio **reference WAV** (embedding) que define:
- Timbre √∫nico
- Sotaque
- Caracter√≠sticas vocais
- Identidade do personagem

**Criar embedding:**
- Colete 5-10 minutos de √°udio limpo do personagem
- Use `create_clean_xtts_embedding.py` para processar e normalizar
- Salve como `{character_id}_xtts_reference_clean.wav`
- Use no XTTS via `speaker_wav` parameter

**VRPG = teatro. Voc√™ precisa de embeddings bem feitos.**

---

## 7. Fluxo Completo (turnos e narrativa)

### üé≠ Entrada de Voz do Jogador

```
[Whisper local] ‚Üí Texto (asr_partial / asr_final)
```

### üß† Interpreta√ß√£o (Pipeline de 2 Modelos)

```
Texto parcial (6-8s) ‚Üí Qwen 1.5B ‚Üí Prel√∫dio emocional (< 1.2s)
    ‚Üì
Texto final ‚Üí Qwen 14B ‚Üí Inten√ß√£o + Fala + Emo√ß√£o completa (< 6s)
```

### üéµ Sistema de Interjei√ß√µes

**Objetivo**: Mascarar lat√™ncia do TTS em respostas longas com interjei√ß√µes pr√©-gravadas.

**Funcionamento**:
- **Detec√ß√£o**: Heur√≠stico `expected_duration = text_length_chars / 25.0`
- **Threshold**: 3.0s (CINEMATIC) ou 4.0s (FAST - mais conservador)
- **Delay**: 1.5s desde fim da fala do jogador at√© in√≠cio da interjei√ß√£o
- **Sele√ß√£o**: Evita repetir √∫ltimas 5 interjei√ß√µes usadas
- **Reprodu√ß√£o**: Interjei√ß√£o ‚Üí Gap (50ms) ‚Üí TTS Principal

**Assets**:
- **Localiza√ß√£o**: `assets-and-models/voices/interjections/`
- **Total**: 53 interjei√ß√µes e frases curtas
- **Formato**: WAV, Float32, 24kHz mono
- **Dura√ß√£o m√©dia**: ~1.9s

**Integra√ß√£o**:
- TTS gera em paralelo enquanto interjei√ß√£o toca
- Elimina "sil√™ncio cognitivo" em respostas longas
- Experi√™ncia natural: DM "pensa" antes de responder

**Ver documenta√ß√£o completa**: [INTERJECTIONS_SYSTEM_COMPLETE.md](../src/tts-service/docs/INTERJECTIONS_SYSTEM_COMPLETE.md)

### üîä Convers√£o Vocal (Streaming Real-Time com Perfis)

**Qwen 1.5B ‚Üí Perfil FAST** (‚â§ 0.8s lat√™ncia):
```
1.5B_output ‚Üí Chunker FAST (30 chars primeiro) ‚Üí XTTS (16 kHz, FP16) ‚Üí FIFO (50ms blocks)
    ‚Üì
AudioBuffer FIFO (Float32 ‚Üí int16)
    ‚Üì
Audio Output Thread (dedicada, WASAPI/ASIO/CoreAudio)
    ‚Üì
Playback cont√≠nuo (zero gaps, pre-buffer 240ms)
```

**Qwen 14B ‚Üí Perfil CINEMATIC** (1.5-3s lat√™ncia):
```
14B_output ‚Üí Chunker CINEMATIC (100 chars primeiro) ‚Üí XTTS (24 kHz, FP16) ‚Üí FIFO (60-80ms blocks)
    ‚Üì
AudioBuffer FIFO (Float32 ‚Üí int16)
    ‚Üì
Audio Output Thread (dedicada, WASAPI/ASIO/CoreAudio)
    ‚Üì
Playback cont√≠nuo (zero gaps, pre-buffer 500ms)
```

**Thread Architecture:**
- **Thread A**: Qwen 1.5B ‚Üí Prelude
- **Thread B**: Qwen 14B ‚Üí Narrative
- **Thread C**: XTTS Worker (adaptive parallel/sequential)
- **Thread D**: Audio Consumer (dedicated I/O, n√£o bloqueia gera√ß√£o)

### üì¢ Reprodu√ß√£o

```
AudioEngine ‚Üí WebRTC ‚Üí Cliente
```

**Regra**: O 1.5B sempre toca antes do 14B para evitar sil√™ncio.

---

## 8. Exemplo de ciclo na pr√°tica

**Jogador:**

"Eu tento persuadir o guarda dizendo que sou emiss√°rio."

**Pipeline:**

1. **Whisper ‚Üí texto parcial (6-8s)**

```
"Eu tento persuadir o guarda..."
```

2. **Qwen 1.5B ‚Üí prel√∫dio emocional (< 1.2s)**

```
"O guarda observa voc√™ com desconfian√ßa."
```

3. **Whisper ‚Üí texto final**

```
"Eu tento persuadir o guarda dizendo que sou emiss√°rio."
```

4. **Qwen 14B ‚Üí narrativa completa (< 6s)**

```xml
<VOICE actor="NPC_Guard" emotion="skeptic" style="dry">
"Emiss√°rio? De qual reino? Mostre sua ins√≠gnia!"
</VOICE>
```

5. **XTTS (para ambos)**

- 1.5B output ‚Üí XTTS (com embedding do personagem) ‚Üí Voz Final (prel√∫dio toca primeiro)
- 14B output ‚Üí XTTS (com embedding do personagem) ‚Üí Voz Final (narrativa completa depois)

üéß **Resultado final ‚Üí NPC real com resposta imediata + narrativa completa**

---

## 9. Dire√ß√£o emocional via tags

Tags obrigat√≥rias que o Orquestrador envia ao XTTS:

- `actor` ‚Üí Define qual embedding usar (qual personagem)
- `emotion` ‚Üí Contexto emocional (pode influenciar pitch/velocidade)
- `style` ‚Üí Estilo de fala
- `volume` ‚Üí Volume relativo
- `pace` ‚Üí Velocidade de fala
- `context` ‚Üí Contexto narrativo

**Exemplo:**

```xml
<VOICE actor="Wizard_Elder"
 emotion="pain"
 style="ancient_whisper"
 pace="slow"
 volume="low">
"Voc√™ tocou o fogo que jamais foi para os vivos‚Ä¶"
</VOICE>
```

**O XTTS usa o embedding do personagem para gerar voz natural e consistente.**

---

## 10. Embeddings XTTS por personagem

**Regra de ouro:**

1 embedding (reference WAV) por personagem importante.

- Protagonista
- Vil√£o
- Companheiros fixos
- NPCs recorrentes

**NPCs "menores"** podem usar embedding gen√©rico OU compartilhar embeddings similares.

**Criar embedding:**
1. Colete 5-10 minutos de √°udio limpo do personagem
2. Use `create_clean_xtts_embedding.py` para processar e normalizar
3. Salve como `{character_id}_xtts_reference_clean.wav`
4. Coloque em `assets-and-models/models/tts/xtts_embeddings/`

---

## 11. Onde o 1.5B e 14B brilham

### Qwen-1.5B:
- Rea√ß√£o humana imediata (< 1.2s)
- Previne sil√™ncio cognitivo
- Cria expectativa e gravidade emocional
- N√£o resolve, apenas antecipa

### Qwen-14B:
- Conex√µes entre sess√µes
- Mem√≥ria narrativa via Vectorizer
- Coer√™ncia de papel social
- Motiva√ß√£o real
- Loucura controlada
- Lore oculto
- Rea√ß√µes / Consequ√™ncias completas

**A combina√ß√£o 1.5B + 14B entrega lat√™ncia humana com qualidade narrativa completa.**

---

## 12. Por que essa arquitetura √© imbat√≠vel

‚ùå **Apenas TTS:**
- rob√≥tico
- pouco est√°vel
- sem acting
- mata a fantasia

‚ùå **Apenas RVC:**
- voz "achatada"
- pobre para mon√≥logos
- bom para vtuber, N√ÉO VRPG

‚úîÔ∏è **Qwen + XTTS (com embeddings):**
- autonomia narrativa
- acting real
- emo√ß√£o cinematogr√°fica
- baixa lat√™ncia
- escal√°vel para 50 NPCs
- qualidade superior (√°udio RAW)

---

## 13. L√≥gica de orquestra√ß√£o (simples e clara)

```yaml
if SPEAKER == PLAYER:
    ‚Üí Whisper ‚Üí Texto para Qwen

if SPEAKER == NPC or MASTER:
    Qwen ‚Üí Fala + Emo√ß√£o
    XTTS(embedding_personagem) ‚Üí √Åudio Final
```

---

## 14. Performance Real (cen√°rio PC)

### Qwen-1.5B (prel√∫dio):
- **Gera√ß√£o**: 200‚Äì500ms
- **XTTS**: 150‚Äì300ms
- **Total**: 350‚Äì800ms (< 1.2s target)

### Qwen-14B (narrativa completa):
- **Gera√ß√£o**: 1.5‚Äì4s (resposta m√©dia), 8‚Äì15s (resposta longa)
- **XTTS Streaming**: 1.2‚Äì2.8s por chunk (RTF 0.4x)
- **Total**: 2.5‚Äì4.0s (inicial) + streaming cont√≠nuo

**Lat√™ncia percebida pelo jogador:**

‚âà 0.6‚Äì1.2s (prel√∫dio) ‚Üí ‚âà 2.5‚Äì4.0s (narrativa completa inicia) ‚Üí streaming cont√≠nuo sem gaps

**Conversa√ß√£o fluida estilo Discord com resposta imediata + streaming cinematogr√°fico**

### Performance por GPU Tier:

| Tier | Lat√™ncia Inicial | RTF | GPU Usage | Pre-Buffer |
|------|------------------|-----|-----------|------------|
| **High-End** (RTX 5090) | 2.5-3.8s | < 0.5x | 80-95% | 2.5s |
| **Mid-Range** (RTX 3070) | 2.5-4.0s | < 0.6x | 60-80% | 1.75s |
| **Modest** (RTX 3050) | 3.0-4.5s | < 0.8x | 40-60% | 1.25s |
| **Low-End** (< 4GB) | 3.5-5.0s | < 1.0x | 30-50% | 0.75s |

**Todos os tiers mant√™m zero-gap playback e sistema responsivo.**

---

## 15. Filosofia

**Texto √© roteiro.**  
**XTTS com embedding √© a voz completa do personagem.**

Voc√™ n√£o est√° programando um chatbot.  
Voc√™ est√° construindo um diretor de RPG com atores reais.

---

## 16. Identificador de fala (UI)

Voc√™ pediu:

> "Indicador mostra quem est√° falando (jogador / mestre / npc)"

**UI acoplada ao mixer:**

- Cada player agent / mestre / npc tem ID de canal
- Playback registra "speaker"
- UI abre highlight no card correspondente
- A anima√ß√£o for√ßa foco do jogador sem atrapalhar input

**Formato:**

- radial glow na portrait
- onda minimalista (n√£o onda de waveform de whatsapp real)

---

## 17. M√∫sica Procedural

**Zero trilha est√°tica codificada.**

Voc√™ quer:

- motivos por ambiente
- intensidade por fase:
  - explorativa
  - social
  - tens√£o
  - combate
  - resultado

**Modelos recomendados:**

- Suno local OFF? (n√£o existe oficialmente)
- Riffusion / Harmonai / AudioLDM locais
- M√∫sica modular ‚Äî loops de 30s‚Äì60s em camadas

**Valor real: camadas.**

**Explora√ß√£o:**

- base pad
- percuss√£o suave
- cordas mornas

**Combate:**

- ativa layer de ritmo
- ativa brass
- subgrave

**Vit√≥ria:**

- corta ritmo
- mant√©m cordas
- sobe arpeggio pequeno

**Morte / derrota:**

- remove paleta alta
- reverb longo
- sub caindo

---

## 18. Sound FX Din√¢mico

**Categoria A ‚Äî ambiente:**

- vento
- chuva
- taverna (copos, murmurinho)
- floresta
- dungeon dripping

**Categoria B ‚Äî a√ß√µes:**

- abrir porta
- pegar item
- passos diferentes (madeira/pedra/√°gua)

**Categoria C ‚Äî combate:**

- espada
- flecha
- magia
- impacto cr√≠tico

**Sistema:**

```
evento ‚Üí envelope ‚Üí mix ‚Üí prioridade
```

**N√£o use wav "cru".**  
Use assets com curva ADSR:

- attack (r√°pido)
- sustain (curto)
- release (programado)

Misturar som seco com ambientes ‚Üí imers√£o.

---

## 19. Callback Narrativo √âpico

Voc√™ pediu:

> "Quando uma condi√ß√£o acaba, o mestre deve ser avisado para narrar."

**Exemplo:**

- Buff dura 5 turnos
- Turno 6 ‚Üí engine manda callback
- Mestre IA responde

> "A centelha rubra deixa seus m√∫sculos‚Ä¶ voc√™ sente o peso de volta."

Isso √© 100% √°udio + narrativa.

O jogador n√£o v√™ "BUFF EXPIROU".  
Ele ouve.

---

## 20. Integra√ß√£o com Turn-based Engine

**Turno ‚â† mensagem de texto.**  
**Turno = momento dram√°tico auditivo.**

**Fluxo:**

1. Engine manda: `EVENT: initiative_rolled`
2. M√∫sica sobe layer "ritmo"
3. SFX toca "switch to combat"
4. Mestre narra
5. Jogadores IA reagem com fala (n√£o com n√∫meros)

**Quando turno conclui:**

- callback: `END_TURN`
- se ningu√©m falar ‚Üí SFX "soft pass"

---

## 21. Perfis Vocais Internos (XTTS Embeddings)

Crie uma estrutura:

```
xtts_embeddings/
    narrator_default_xtts_reference_clean.wav
    npc_guard_xtts_reference_clean.wav
    npc_barkeep_xtts_reference_clean.wav
    npc_mysterious_woman_xtts_reference_clean.wav
    race_drow_xtts_reference_clean.wav
    monster_undead_xtts_reference_clean.wav
```

**Cada embedding XTTS:**

- reference WAV processado e normalizado
- 5-10 minutos de √°udio limpo do personagem
- caracter√≠sticas vocais preservadas
- qualidade RAW (sem processamento adicional)

**1 embedding por personagem importante.**  
**NPCs menores podem compartilhar embeddings similares.**

**Criar embedding:**
- Use `create_clean_xtts_embedding.py` para processar dataset
- Salve como `{character_id}_xtts_reference_clean.wav`
- Use no XTTS via `speaker_wav` parameter

---

## 22. Whisper Local

**Whisper tiny / small GPU:**

- ideal para ingl√™s
- responde <80ms
- lat√™ncia zero de rede
- integra√ß√£o direta no client

**Jogador fala ‚Üí evento RAW ‚Üí IA reage.**

**Sem PTT (push to talk) se poss√≠vel:**

- detecte in√≠cio/fim de fala por amplitude RMS
- evita mec√¢nica de "r√°dio Discord" dentro do RPG

---

## 23. Emulando Mesa REAL (dica psicol√≥gica)

**A voz nunca deve come√ßar abrupta:**

- fade-in de 30‚Äì50ms

**A m√∫sica nunca para instant√¢nea:**

- crossfade 400‚Äì900ms

Voc√™ n√£o est√° "tocando √°udio".  
Est√° controlando emo√ß√£o.

---

## 24. Mobile vs PC

**PC (GPU dispon√≠vel)**

- Qwen 1.5B q4_K_M (rea√ß√£o r√°pida)
- Qwen 14B q4_K_M (narrativa completa)
- XTTS v2 (s√≠ntese com embeddings por personagem)
- FX + m√∫sica din√¢micos

**Mobile**

- Client n√£o renderiza √°udio complexo.
- Ele streama PCM do servidor host da sess√£o (mestre).
- EVC local (leve)
- mix parcial
- cache de samples
- nunca gerar TTS local mobile

---

## 25. Docker & Deploy

**Ideal:**

- Cont√™iner de voz
- Cont√™iner de FX
- Cont√™iner de m√∫sica procedural

**Cada um exp√µe API interna:**

- `generate_voice(text, character_embedding_path)`
- `play_sfx(event_id)`
- `music_state(phase)`

**Sem API externa web.**

---

## 26. Falhas / fallback

**Se TTS travar:**

- avatar UI pisca
- narra√ß√£o √© substitu√≠da por texto
- engine "preenche sil√™ncio"

**Sem "bugs aud√≠veis".**

---

## 27. Benef√≠cio REAL do sistema

VRPG n√£o √© Foundry com VTTS.

Voc√™ tem:

- mestre que respira
- NPCs que soam vivos
- jogadores IA que discutem
- m√∫sica que reage
- combate que soa pesado

Isso entrega imers√£o de Critical Role para 1 pessoa ‚Äî em local.

---

## 28. Voice INTENTS (Design T√©cnico e Funcional)

Este sistema define **a API de alto n√≠vel** que o Mestre IA utiliza para produzir VOZ em runtime, sem API externa, com baixa lat√™ncia e coer√™ncia dram√°tica.

### Filosofia Central

Voz n√£o √© "speech synthesis". **Voz √© contexto dram√°tico.**

O VRPG usa INTENTS de voz que funcionam como **ordens direcionais**, nunca como texto bruto do LLM.

O Mestre n√£o produz um √°udio "quando quer". Ele produz √°udio **quando uma INTENT de voz √© acionada**.

Isso permite:
- menor lat√™ncia
- ritmo natural
- sincroniza√ß√£o com m√∫sica e efeitos
- UI consistente (quem est√° falando)

### Estrutura de Intent

**Formato (sempre)**:
```
[VOICE_INTENT:<tipo>]
payload {
speaker: enum,
style: enum,
emotion: enum,
text: string,
meta: {...}
}
```

> O **LLM N√ÉO gera √°udio**. Ele **gera a INTENT**, e o m√≥dulo de voz executa o √°udio.

### Categorias de VOICE_INTENT

#### VOZ_MESTRE
Narra o mundo, descreve ambientes, resolve transforma√ß√µes.

```
[VOICE_INTENT:NARRATE]
{
speaker: "mestre",
style: "neutral",
emotion: "calm",
text: "O corredor √© estreito, iluminado por tochas antigas."
}
```

**Uso**: Introdu√ß√µes de cena, descri√ß√µes de ambiente, resolu√ß√£o de a√ß√µes fora de combate, escalonamento narrativo.

#### VOZ_NPC
O Mestre IA interpreta um personagem espec√≠fico.

```
[VOICE_INTENT:NPC_DIALOGUE]
{
speaker: "npc_guard",
style: "gravel_low",
emotion: "mild_irritation",
text: "N√£o tenho tempo pra voc√™s. Sigam andando."
}
```

**Notas**: `speaker` deve apontar para **perfil vocal** carregado. `emotion` ajusta pitch/ritmo. NPC n√£o fala sobre mec√¢nica.

#### VOZ_PLAYER_IA
Jogadores IA interpretam seus personagens de forma dieg√©tica.

```
[VOICE_INTENT:PLAYER_DIALOGUE]
{
speaker: "player_rogue",
style: "casual",
emotion: "amused",
text: "Relaxa... eu abro a porta. S√≥ preparou a magia, n√©?"
}
```

**Regras**: Nunca explicar status mec√¢nico. Reagir emocionalmente a eventos. Interagir como humano real numa mesa.

#### VOZ_EVENT (combat / drama)
Trilhas de √°udio narrativas r√°pidas para **impacto psicol√≥gico**.

```
[VOICE_INTENT:EVENT]
{
speaker: "mestre",
style: "intense",
emotion: "danger",
text: "O ogro avan√ßa e a sala inteira treme com o impacto."
}
```

**Uso**: Entrada de boss, desastre ambiental, trai√ß√£o / revela√ß√£o.

#### VOZ_CONDI√á√ÉO
Condi√ß√µes tempor√°rias **terminando** ou **iniciando**.

```
[VOICE_INTENT:CONDITION_EXPIRE]
{
speaker: "mestre",
style: "neutral",
emotion: "solemn",
text: "A energia rubra abandona seus m√∫sculos. A dor retorna."
}
```

> N√£o "+2 acabou". S√≥ narra√ß√£o dieg√©tica.

#### VOZ_SISTEMA
Mensagens de seguran√ßa **sem quebrar a fic√ß√£o**.

```
[VOICE_INTENT:SYSTEM]
{
speaker: "mestre",
style: "low",
emotion: "neutral",
text: "Preciso de alguns segundos para organizar a cena."
}
```

**Contextos**: carga de assets, lat√™ncia moment√¢nea, delays de GPU.

### Modelo de Di√°logo Din√¢mico

A IA **n√£o narra mon√≥logos de 40 segundos**. Ela cria **turnos emocionais curtos**.

Exemplo:
```
[VOICE_INTENT:NPC_DIALOGUE] ‚Äî 2s
[VOICE_INTENT:PLAYER_DIALOGUE] ‚Äî 1.5s
[VOICE_INTENT:NARRATE] ‚Äî 3s
```

> √â ritmo teatral. RPG √© micro-jazz conversacional.

### Multiplicidade de Vozes

**Perfis vocais = skin de √°udio.**

Em runtime, n√£o re-treine modelo TTS. Voc√™ troca perfis:
- `npc_barkeep`
- `npc_royal_guard`
- `npc_old_sage`
- `villain_primary`
- `monster_shadow`

Cada perfil possui: pitch base, tempo base, instabilidade, "grain".

### Perfis de Voz e Emocionais

Um perfil pode falar com v√°rias emo√ß√µes.

Ex:
```
speaker: "npc_barkeep",
style: "warm_low",
emotion: "fear"
```

Evitar:
```
speaker: "npc_barkeep",
emotion: "screaming rage"
```
se ele √© t√≠mido/quieto.

**Emocionalidade sempre coerente com personagem.**

### Integra√ß√£o com M√∫sica

O √°udio controla a m√∫sica, n√£o o contr√°rio.

Exemplo:
- **Iniciativa rolada**: `[VOICE_INTENT:EVENT] ‚Üí m√∫sica sobe layer_rhythm` + `[SFX:MILITIA_GONG]`
- **Combate encerrado**: `[VOICE_INTENT:NARRATE] ‚Üí m√∫sica cai ‚Üí layer_relief`

### Integra√ß√£o com FX

Efeito **n√£o interrompe fala**. Fala sempre PRIORIDADE.

Quando evento clim√°tico √© narrado, a engine sonoriza:
```
[VOICE_INTENT:NARRATE]
"A chuva escorre pelas pedras..."

‚Üí [SFX:RAIN_LIGHT_LOOP]
```

### Whisper ‚Üí INTENT

Pipeline social:
```
jogador humano fala ‚Üí
whisper local ‚Üí texto ‚Üí
Mestre IA pensa ‚Üí
gera INTENT ‚Üí
motor TTS reproduz.
```

Ele n√£o retorna text√£o infinito: fala no tom correto com emo√ß√£o.

### Prioriza√ß√£o

| Prioridade | Tipo |
|---|---|
| 1 | VOICE_INTENT:NARRATE |
| 2 | PLAYER_DIALOGUE |
| 3 | NPC_DIALOGUE |
| 4 | EVENT |
| 5 | FX |
| 6 | MUSIC |

### Tempos de pausa (importante)

- 200‚Äì600ms entre falas
- 1000‚Äì2000ms ap√≥s revela√ß√µes
- 500‚Äì800ms antes de decis√£o t√°tica

Isso gera **dramaturgia**.

### Modo Falha de Voz

Se TTS ou perfil falhar:
- UI exibe texto do mestre
- m√∫sica baixa
- indicador visual mostra "voz indispon√≠vel"
- nunca som rob√≥tico glitchado

### Anti-spam

O Mestre IA nunca envia 10 falas seguidas. Ele passa a vez √† party IA ou ao jogador humano.

### Linguagem proibida

- "+5 de CA"
- "Use DEX"
- "Voc√™ tem vantagem / desvantagem"

**Sempre metaf√≥rico.**

### Linguagem ideal

- fisiol√≥gica (respira√ß√£o, fadiga)
- espacial (press√£o, eco)
- emocional (raiva, medo)
- est√©tica (luz, textura, som)

### API Interna (para engine)

Audio Engine exp√µe:
```
queue_voice(intent)
stop_voice()
play_sfx(event_id)
set_music_state(state)
```

UI consome:
```
on_voice_speaker(id:string)
```

### Output Final

> A voz do jogo n√£o √© "fala do modelo". √â um **teatro auditivo** controlado por INTENTS.

Narrador cria mundo. NPCs respiram nele. Jogadores IA conversam com voc√™. M√∫sica acompanha. FX refor√ßa.

**Tudo local. Sem API. Sem streaming externo.**

---

## 29. Resumo Final em 1 frase

> **Som = emo√ß√£o.**  
> Voz √© o narrador invis√≠vel que cola a fic√ß√£o na psique do jogador.  
> Por isso o √°udio deve ser local, vivo e instant√¢neo.  
> O pipeline 1.5B ‚Üí 14B ‚Üí XTTS garante resposta imediata sem sacrificar qualidade narrativa.  
> **√Åudio RAW do XTTS = qualidade perfeita, sem processamento que degrada.**

---

## Refer√™ncias

- [PIPELINE_ARCHITECTURE.md](PIPELINE_ARCHITECTURE.md) - Arquitetura completa do pipeline
- [QWEN_1_5B_SPEC.md](QWEN_1_5B_SPEC.md) - Especifica√ß√£o do Qwen-1.5B
- [QWEN_14B_SPEC.md](QWEN_14B_SPEC.md) - Especifica√ß√£o do Qwen-14B
- [ORCHESTRATOR.md](ORCHESTRATOR.md) - Especifica√ß√£o do orquestrador

