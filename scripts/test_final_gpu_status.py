#!/usr/bin/env python3
"""Resumo final do status GPU"""

import torch

print("=" * 70)
print("‚úÖ VERIFICA√á√ÉO FINAL - STATUS GPU")
print("=" * 70)
print()

print(f"üì¶ PyTorch: {torch.__version__}")
print(f"üîß CUDA Build: {torch.version.cuda}")
print(f"üéÆ CUDA Available: {torch.cuda.is_available()}")
print()

if torch.cuda.is_available():
    print(f"üñ•Ô∏è  GPU: {torch.cuda.get_device_name(0)}")
    print(f"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    print(f"‚ö° CUDA Capability: {torch.cuda.get_device_capability(0)}")
    print()
    
    # Teste pr√°tico
    try:
        x = torch.randn(1000, 1000).cuda()
        y = torch.randn(1000, 1000).cuda()
        z = torch.matmul(x, y)
        print("‚úÖ Teste CUDA: SUCESSO!")
    except Exception as e:
        print(f"‚ùå Erro no teste: {e}")
    
    print()
    print("=" * 70)
    print("‚úÖ TUDO FUNCIONANDO! GPU est√° pronta para uso!")
    print("=" * 70)
    
    # Verificar XTTS
    print()
    print("Testando XTTS com GPU...")
    try:
        from TTS.api import TTS
        tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2', gpu=True)
        print("‚úÖ XTTS carregado com GPU!")
    except Exception as e:
        print(f"‚ö†Ô∏è  XTTS: {e}")
else:
    print("‚ùå CUDA n√£o est√° dispon√≠vel")

