#!/usr/bin/env python3
"""
Gera APENAS os √°udios problem√°ticos corrigidos
Vers√£o com prompts otimizados para evitar ru√≠dos, repeti√ß√µes e cortes estranhos
"""

import sys
import os
import time
from pathlib import Path

# Configurar encoding para UTF-8
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# Aceitar termos de servi√ßo do Coqui TTS
os.environ["COQUI_TOS_AGREED"] = "1"

script_dir = Path(__file__).parent
base_dir = script_dir.parent.parent.parent.parent

try:
    import soundfile as sf
    import torch
    import torchaudio
    from TTS.api import TTS
    import numpy as np
except ImportError as e:
    print(f"‚ùå ERRO: Depend√™ncias n√£o encontradas: {e}", file=sys.stderr)
    print("   Instale: pip install TTS soundfile torch torchaudio", file=sys.stderr)
    sys.exit(1)

# --- Fix para PyTorch 2.6+ ---
original_load = torch.load
def patched_load(*args, **kwargs):
    if 'weights_only' not in kwargs:
        kwargs['weights_only'] = False
    return original_load(*args, **kwargs)
torch.load = patched_load

# --- Monkey Patch para torchaudio.load ---
_original_torchaudio_load = torchaudio.load

def patched_torchaudio_load(filepath, *args, **kwargs):
    try:
        return _original_torchaudio_load(filepath, *args, **kwargs)
    except (RuntimeError, ImportError, OSError) as e:
        error_str = str(e).lower()
        if any(keyword in error_str for keyword in ["torchcodec", "ffmpeg", "dll", "libtorchcodec"]):
            try:
                audio, sr = sf.read(filepath)
                if len(audio.shape) == 1:
                    audio = audio.reshape(1, -1)
                elif len(audio.shape) == 2 and audio.shape[0] > audio.shape[1]:
                    audio = audio.T
                audio_tensor = torch.from_numpy(audio.copy()).float()
                return audio_tensor, int(sr)
            except Exception as sf_error:
                raise RuntimeError(
                    f"Failed to load audio with both torchcodec and soundfile. "
                    f"torchcodec error: {e}, soundfile error: {sf_error}"
                ) from e
        else:
            raise

torchaudio.load = patched_torchaudio_load
# --- Fim Monkey Patch ---

# APENAS os 4 arquivos problem√°ticos restantes com textos otimizados
# Estrat√©gia: textos curtos, pontua√ß√£o final clara, sem retic√™ncias que causam ru√≠do
FIX_TEXTS = {
    "dm_hmm_03": "Hmm",  # Sem pontua√ß√£o (vers√£o alternativa) - melhorar limpeza final
    "dm_so_01": "So,",  # Adicionar v√≠rgula para evitar pron√∫ncia com Z
    "dm_so_03": "So,",  # Segunda vers√£o com v√≠rgula
    "dm_uh_01": "Uh",  # Sem pontua√ß√£o - melhorar corte final
}

def generate_fixes():
    """Gera APENAS os arquivos problem√°ticos corrigidos"""
    print("\n" + "="*70)
    print("  CORRE√á√ÉO DE INTERJEI√á√ïES PROBLEM√ÅTICAS")
    print("="*70)
    
    # Verificar GPU
    use_gpu = torch.cuda.is_available()
    if use_gpu:
        gpu_name = torch.cuda.get_device_name(0)
        print(f"\nüéÆ GPU: {gpu_name}")
    else:
        print("\nüíª Usando CPU")
    
    # Carregar modelo XTTS
    print("\nüì• Carregando modelo XTTS v2...")
    try:
        tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2", gpu=use_gpu, progress_bar=False)
        print("‚úÖ Modelo XTTS carregado!")
        
        # Configurar FP16
        if use_gpu and torch.cuda.is_available():
            try:
                if hasattr(tts, 'synthesizer') and hasattr(tts.synthesizer, 'model'):
                    tts.synthesizer.model = tts.synthesizer.model.half().cuda()
                    print("‚úÖ Modelo configurado para FP16")
            except Exception as e:
                print(f"‚ö†Ô∏è  N√£o foi poss√≠vel configurar FP16: {e}")
        
        # Warm-up
        print("üî• Executando warm-up...")
        with torch.inference_mode():
            _ = tts.tts("Warmup", speaker="Ana Florence", language="en")
        print("‚úÖ Warm-up conclu√≠do")
        
    except Exception as e:
        print(f"‚ùå ERRO ao carregar modelo: {e}", file=sys.stderr)
        sys.exit(1)
    
    # Criar diret√≥rio de sa√≠da (subpasta dentro de interjections)
    output_dir = Path(r"G:\vrpg\vrpg-client\assets-and-models\voices\interjections\fix")
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"\nüìÅ Diret√≥rio de sa√≠da: {output_dir}")
    
    # Gerar apenas os arquivos problem√°ticos
    print(f"\nüéµ Gerando {len(FIX_TEXTS)} arquivos corrigidos...\n")
    
    results = []
    
    for clip_id, text in FIX_TEXTS.items():
        print(f"üé§ {clip_id}: '{text}'")
        
        try:
            # Gerar √°udio
            start_time = time.time()
            with torch.inference_mode():
                audio = tts.tts(text, speaker="Ana Florence", language="en")
            gen_time = time.time() - start_time
            
            # Converter para numpy se necess√°rio
            if isinstance(audio, list):
                audio = np.array(audio)
            
            # Converter para mono se necess√°rio
            if len(audio.shape) > 1:
                audio = np.mean(audio, axis=0)
            
            # Obter sample rate
            sample_rate = tts.synthesizer.output_sample_rate
            
            # Calcular dura√ß√£o
            duration = len(audio) / sample_rate
            
            # Remover sil√™ncio final excessivo e ru√≠dos (mais agressivo)
            # Isso ajuda a evitar ru√≠dos, cortes estranhos e sons aleat√≥rios
            threshold = 0.005  # Threshold mais baixo para detectar ru√≠dos sutis
            silence_samples = int(sample_rate * 0.2)  # 0.2s de sil√™ncio m√°ximo (mais agressivo)
            
            # Encontrar √∫ltimo ponto com √°udio significativo
            abs_audio = np.abs(audio)
            last_non_silent = len(audio) - 1
            
            # Procurar do final para o in√≠cio, encontrando o √∫ltimo som significativo
            for i in range(len(audio) - 1, max(0, len(audio) - silence_samples * 2), -1):
                # Verificar janela de 0.05s para evitar ru√≠dos pontuais
                window_size = int(sample_rate * 0.05)
                window_start = max(0, i - window_size)
                window_avg = np.mean(abs_audio[window_start:i+1])
                
                if window_avg > threshold:
                    last_non_silent = i
                    break
            
            # Adicionar fade-out mais longo (0.1s) para evitar corte abrupto e ru√≠dos
            fade_samples = int(sample_rate * 0.1)
            fade_start = max(0, last_non_silent - fade_samples)
            fade_end = min(len(audio), last_non_silent + int(sample_rate * 0.05))
            
            # Aplicar fade-out suave
            if fade_end > fade_start:
                fade_curve = np.linspace(1.0, 0.0, fade_end - fade_start)
                audio[fade_start:fade_end] *= fade_curve
            
            # Cortar sil√™ncio final excessivo (deixar apenas 0.05s para evitar ru√≠dos)
            final_silence = int(sample_rate * 0.05)
            audio = audio[:min(len(audio), last_non_silent + final_silence)]
            
            duration = len(audio) / sample_rate
            print(f"   ‚úÖ Dura√ß√£o: {duration:.2f}s (ap√≥s limpeza)")
            
            # Salvar arquivo
            output_file = output_dir / f"{clip_id}.wav"
            
            # Salvar como Float32 mono (qualidade m√°xima)
            sf.write(
                str(output_file),
                audio.astype(np.float32),
                sample_rate,
                subtype='FLOAT'
            )
            
            print(f"   üíæ Salvo: {output_file}")
            print(f"   ‚è±Ô∏è  Tempo de gera√ß√£o: {gen_time:.3f}s\n")
            
            results.append({
                'id': clip_id,
                'text': text,
                'duration': duration,
                'file': str(output_file),
                'gen_time': gen_time,
            })
            
        except Exception as e:
            print(f"   ‚ùå Erro ao gerar {clip_id}: {e}\n")
            import traceback
            traceback.print_exc()
    
    # Resumo
    print("="*70)
    print("  RESUMO")
    print("="*70)
    
    total_duration = sum(r['duration'] for r in results)
    total_gen_time = sum(r['gen_time'] for r in results)
    avg_duration = total_duration / len(results) if results else 0
    max_duration_found = max((r['duration'] for r in results), default=0)
    min_duration_found = min((r['duration'] for r in results), default=0)
    
    print(f"\nüìä Estat√≠sticas:")
    print(f"   Total de arquivos corrigidos: {len(results)}")
    print(f"   Dura√ß√£o m√©dia: {avg_duration:.2f}s")
    print(f"   Dura√ß√£o m√≠nima: {min_duration_found:.2f}s")
    print(f"   Dura√ß√£o m√°xima: {max_duration_found:.2f}s")
    print(f"   Total de √°udio: {total_duration:.2f}s")
    print(f"   Tempo total de gera√ß√£o: {total_gen_time:.2f}s")
    
    print(f"\nüìÅ Arquivos salvos em: {output_dir}")
    print("\n" + "="*70 + "\n")
    
    return results

if __name__ == "__main__":
    results = generate_fixes()
    
    # Criar arquivo de resumo
    summary_file = Path(__file__).parent / "interjections_fix_summary.md"
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("# Interjei√ß√µes Corrigidas\n\n")
        f.write(f"**Data**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**Total**: {len(results)} arquivos corrigidos\n\n")
        f.write("| ID | Texto | Dura√ß√£o (s) | Arquivo |\n")
        f.write("|----|-------|-------------|----------|\n")
        for r in results:
            f.write(f"| {r['id']} | {r['text']} | {r['duration']:.2f} | {Path(r['file']).name} |\n")
    
    print(f"üìÑ Resumo salvo em: {summary_file}")

