#!/usr/bin/env python3
"""
Teste do XTTS com voz personalizada usando parÃ¡grafo de livro
"""

import sys
import os
from pathlib import Path
import numpy as np

# Aceitar termos de serviÃ§o do Coqui TTS
os.environ["COQUI_TOS_AGREED"] = "1"

# Adicionar o diretÃ³rio do SoVITS ao path
script_dir = Path(__file__).parent
sovits_dir = script_dir.parent.parent.parent.parent / "assets-and-models" / "models" / "tts" / "sovits"
sys.path.insert(0, str(sovits_dir))

try:
    from TTS.api import TTS
    import torch
    import soundfile as sf
    import torchaudio
    from scipy import signal
except ImportError as e:
    print(f"âŒ ERRO: DependÃªncias nÃ£o encontradas: {e}", file=sys.stderr)
    print("   Instale scipy: pip install scipy", file=sys.stderr)
    sys.exit(1)

# Fix para PyTorch 2.6+
original_load = torch.load
def patched_load(*args, **kwargs):
    if 'weights_only' not in kwargs:
        kwargs['weights_only'] = False
    return original_load(*args, **kwargs)
torch.load = patched_load

# Monkey patch torchaudio.load para usar soundfile (evita problema do torchcodec)
original_torchaudio_load = torchaudio.load
def patched_torchaudio_load(filepath, *args, **kwargs):
    try:
        # Tentar carregar com soundfile primeiro
        audio, sr = sf.read(filepath)
        # Converter para tensor no formato esperado pelo torchaudio
        if len(audio.shape) == 1:
            audio = audio.reshape(1, -1)  # [channels, samples]
        audio_tensor = torch.from_numpy(audio).float()
        return audio_tensor, sr
    except:
        # Fallback para mÃ©todo original
        return original_torchaudio_load(filepath, *args, **kwargs)

torchaudio.load = patched_torchaudio_load


def test_xtts_with_book_paragraph(use_original_embedding=False):
    """Testa XTTS com voz personalizada usando parÃ¡grafo de livro"""
    print("\n" + "="*70)
    print("  TESTE: XTTS com Voz Personalizada - ParÃ¡grafo de Livro")
    print("="*70 + "\n")
    
    # Escolher qual embedding usar
    if use_original_embedding:
        # Usar embedding original (sem limpeza)
        reference_wav = script_dir / "dungeon_master_en_xtts_reference.wav"
        embedding_type = "ORIGINAL (sem limpeza)"
    else:
        # Usar embedding limpo (padrÃ£o)
        reference_wav = script_dir / "dungeon_master_en_xtts_reference_clean.wav"
        embedding_type = "LIMPO (processado)"
        # Fallback para versÃ£o antiga se a limpa nÃ£o existir
        if not reference_wav.exists():
            reference_wav = script_dir / "dungeon_master_en_xtts_reference.wav"
            embedding_type = "ORIGINAL (fallback)"
    
    if not reference_wav.exists():
        print(f"âŒ ERRO: Arquivo de referÃªncia nÃ£o encontrado: {reference_wav}")
        print("   Execute primeiro: create_xtts_embedding.py")
        sys.exit(1)
    
    print(f"âœ… Arquivo de referÃªncia encontrado: {reference_wav.name}")
    print(f"   Tipo: {embedding_type}")
    
    # ParÃ¡grafo de exemplo de um livro (fantasia/RPG)
    book_paragraph = """In the depths of the ancient dungeon, shadows danced along the stone walls as torchlight flickered. The air was thick with the scent of damp earth and something elseâ€”something that made the hairs on the back of your neck stand on end. You could hear the distant echo of water dripping, each drop a reminder that you were far from the safety of the surface. The corridor stretched before you, disappearing into darkness, and you knew that whatever lay ahead would test not just your strength, but your very resolve."""
    
    print(f"\nðŸ“– ParÃ¡grafo de teste ({len(book_paragraph)} caracteres):")
    print("-" * 70)
    print(book_paragraph)
    print("-" * 70)
    
    # Carregar modelo XTTS
    print("\nðŸ“¥ Carregando modelo XTTS v2...")
    try:
        use_gpu = torch.cuda.is_available()
        device = "cuda" if use_gpu else "cpu"
        print(f"   Dispositivo: {device}")
        
        tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2", gpu=use_gpu, progress_bar=True)
        print("âœ… Modelo XTTS carregado!\n")
    except Exception as e:
        print(f"âŒ ERRO ao carregar modelo: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # Testar sÃ­ntese com voz personalizada
    print(f"ðŸŽ™ï¸  Sintetizando parÃ¡grafo com voz personalizada do dungeon master...")
    print(f"   Usando: {reference_wav.name}\n")
    
    try:
        import time
        import re
        
        # PrÃ©-processar texto para melhor segmentaÃ§Ã£o
        # Adicionar espaÃ§os apÃ³s pontuaÃ§Ã£o para melhor divisÃ£o
        processed_text = re.sub(r'([.!?])([A-Z])', r'\1 \2', book_paragraph)
        processed_text = re.sub(r'([.!?])\s+', r'\1 ', processed_text)  # Normalizar espaÃ§os
        
        print("ðŸ“ Texto prÃ©-processado para melhor segmentaÃ§Ã£o")
        print(f"   Original: {len(book_paragraph)} caracteres")
        print(f"   Processado: {len(processed_text)} caracteres\n")
        
        start_time = time.time()
        
        # Usar sÃ­ntese com melhor controle de segmentaÃ§Ã£o
        # O XTTS internamente divide em sentenÃ§as, entÃ£o vamos garantir que o texto estÃ¡ bem formatado
        audio = tts.tts(
            text=processed_text,
            speaker_wav=str(reference_wav),  # Usar arquivo de referÃªncia personalizado
            language="en",
            # Adicionar pequena pausa entre sentenÃ§as para evitar sobreposiÃ§Ã£o
            # (parÃ¢metros podem variar dependendo da versÃ£o do TTS)
        )
        
        synthesis_time = time.time() - start_time
        
        print(f"âœ… Ãudio gerado com sucesso!")
        print(f"   - Amostras: {len(audio)}")
        print(f"   - Sample rate: {tts.synthesizer.output_sample_rate} Hz")
        print(f"   - DuraÃ§Ã£o: {len(audio) / tts.synthesizer.output_sample_rate:.2f}s")
        print(f"   - Tempo de sÃ­ntese: {synthesis_time:.2f}s")
        print(f"   - Real-time factor: {synthesis_time / (len(audio) / tts.synthesizer.output_sample_rate):.2f}x")
        
        # Converter para numpy (evitar mÃºltiplas conversÃµes)
        print("\nðŸ’¾ Salvando Ã¡udio RAW (sem processamento)...")
        print("   âœ… Descoberta: RAW Ã© infinitamente melhor que qualquer processamento!")
        
        # Converter de forma eficiente (evitar mÃºltiplas conversÃµes)
        if isinstance(audio, torch.Tensor):
            audio_np = audio.cpu().numpy().astype(np.float32)  # Converter direto para float32
        elif isinstance(audio, np.ndarray):
            audio_np = audio.astype(np.float32)  # Garantir float32
        else:
            audio_np = np.array(audio, dtype=np.float32)  # Converter para float32
        
        # Garantir que Ã© 1D (sem cÃ³pia se jÃ¡ for 1D)
        if len(audio_np.shape) > 1:
            audio_np = audio_np.flatten()
        
        sr = tts.synthesizer.output_sample_rate
        
        # SALVAR APENAS RAW (sem processamento nenhum - Ã© o melhor resultado!)
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        embedding_suffix = "original" if use_original_embedding else "clean"
        
        # Salvar versÃ£o com timestamp
        output_path_timestamped = script_dir / f"test_book_paragraph_xtts_{embedding_suffix}_{timestamp}.wav"
        # Salvar RAW em Float32 (sem quantizaÃ§Ã£o, sem processamento)
        sf.write(str(output_path_timestamped), audio_np, sr, subtype='FLOAT')
        
        # TambÃ©m salvar versÃ£o "latest" para referÃªncia
        output_path_latest = script_dir / f"test_book_paragraph_xtts_{embedding_suffix}_latest.wav"
        sf.write(str(output_path_latest), audio_np, sr, subtype='FLOAT')
        
        print(f"   âœ… Ãudio RAW salvo (Float32, sem processamento)")
        print(f"\nðŸ’¾ Arquivos salvos:")
        print(f"   - Timestamped: {output_path_timestamped.name}")
        print(f"   - Latest: {output_path_latest.name}")
        print(f"\nðŸ“Š Processo aplicado (RAW - MELHOR RESULTADO):")
        print(f"   âœ… SEM processamento (direto do XTTS)")
        print(f"   âœ… SEM filtros (evita delay/robÃ³tico)")
        print(f"   âœ… SEM DC offset removal (evita artefatos)")
        print(f"   âœ… SEM fade (evita artefatos)")
        print(f"   âœ… SEM normalizaÃ§Ã£o (preserva original)")
        print(f"   âœ… Float32 WAV (sem quantizaÃ§Ã£o Int16/Int24)")
        print(f"   âœ… ConversÃ£o mÃ­nima (Tensor â†’ NumPy float32 direto)")
        print(f"   âœ… Embedding: {embedding_type}")
        print(f"\nðŸŽ¯ CONCLUSÃƒO: O XTTS jÃ¡ gera Ã¡udio perfeito - processamento sÃ³ degrada!")
        print(f"\nðŸŽ§ Compare com versÃµes anteriores para verificar a melhoria!")
        print("="*70 + "\n")
        
    except Exception as e:
        print(f"âŒ ERRO ao sintetizar: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    # Aceitar argumento para usar embedding original
    use_original = False
    if len(sys.argv) > 1:
        if sys.argv[1] in ["--original", "-o", "original"]:
            use_original = True
            print("ðŸ“Œ Usando embedding ORIGINAL (sem limpeza)")
        elif sys.argv[1] in ["--help", "-h", "help"]:
            print("Uso: test_xtts_book_paragraph.py [--original|-o]")
            print("  --original, -o: Usa o embedding original (sem limpeza)")
            print("  (sem argumentos): Usa o embedding limpo (padrÃ£o)")
            sys.exit(0)
    
    test_xtts_with_book_paragraph(use_original_embedding=use_original)

