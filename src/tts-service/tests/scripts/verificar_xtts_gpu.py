#!/usr/bin/env python3
"""Verifica se XTTS est√° usando GPU"""

import sys
import os
import torch

# Aceitar termos de servi√ßo do Coqui TTS
os.environ["COQUI_TOS_AGREED"] = "1"

# Fix para PyTorch 2.6+ que requer weights_only=False
original_load = torch.load
def patched_load(*args, **kwargs):
    if 'weights_only' not in kwargs:
        kwargs['weights_only'] = False
    return original_load(*args, **kwargs)
torch.load = patched_load

# Tentar adicionar safe globals
try:
    from TTS.tts.configs.xtts_config import XttsConfig
    from TTS.tts.models.xtts import XttsAudioConfig, XttsArgs
    torch.serialization.add_safe_globals([XttsConfig, XttsAudioConfig, XttsArgs])
except:
    pass

print("="*70)
print("üîç VERIFICA√á√ÉO XTTS GPU")
print("="*70)

print(f"\nüì¶ PyTorch: {torch.__version__}")
print(f"üîß CUDA Build: {torch.version.cuda}")
print(f"üéÆ CUDA Dispon√≠vel: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"üñ•Ô∏è  GPU: {torch.cuda.get_device_name(0)}")
    print(f"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    print(f"‚ö° CUDA Capability: {torch.cuda.get_device_capability(0)}")
    
    print("\nüì• Carregando XTTS com GPU=True...")
    try:
        from TTS.api import TTS
        tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2', gpu=True, progress_bar=False)
        print("‚úÖ XTTS carregado!")
        
        # Verificar device do modelo de v√°rias formas
        using_gpu = False
        
        # M√©todo 1: Verificar device do synthesizer
        try:
            device = str(tts.synthesizer.device)
            print(f"üîß Device do synthesizer: {device}")
            using_gpu = "cuda" in device.lower()
        except:
            pass
        
        # M√©todo 2: Verificar device do modelo TTS
        if not using_gpu:
            try:
                model_device = next(tts.synthesizer.tts_model.parameters()).device
                print(f"üîß Device do modelo TTS: {model_device}")
                using_gpu = "cuda" in str(model_device).lower()
            except:
                pass
        
        # M√©todo 3: Fazer s√≠ntese de teste e verificar onde est√° rodando
        if not using_gpu:
            print("\nüß™ Fazendo s√≠ntese de teste para verificar device...")
            try:
                import time
                start = time.time()
                audio = tts.tts("Hello", speaker="Ana Florence", language="en")
                elapsed = time.time() - start
                print(f"‚è±Ô∏è  Tempo de s√≠ntese: {elapsed:.3f}s")
                
                # Se for muito r√°pido (< 0.5s), provavelmente est√° em GPU
                # Se for lento (> 2s), provavelmente est√° em CPU
                if elapsed < 0.5:
                    using_gpu = True
                    print("‚úÖ S√≠ntese r√°pida indica uso de GPU")
                elif elapsed > 2.0:
                    using_gpu = False
                    print("‚ö†Ô∏è  S√≠ntese lenta indica uso de CPU")
                else:
                    print("‚ö†Ô∏è  Tempo intermedi√°rio - n√£o √© poss√≠vel determinar com certeza")
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro no teste: {e}")
        
        print(f"\nüéØ Usando GPU: {'‚úÖ SIM' if using_gpu else '‚ùå N√ÉO'}")
        
        if using_gpu:
            print("\n‚úÖ XTTS est√° configurado e usando GPU!")
            print("   Lat√™ncia esperada: 50-200ms por s√≠ntese")
        else:
            print("\n‚ö†Ô∏è  XTTS N√ÉO est√° usando GPU!")
            print("   Lat√™ncia esperada: 3-30 segundos por s√≠ntese")
            print("   Verifique a configura√ß√£o do TTS")
            
    except Exception as e:
        print(f"‚ùå Erro ao carregar XTTS: {e}")
        import traceback
        traceback.print_exc()
else:
    print("\n‚ùå CUDA n√£o dispon√≠vel - XTTS usar√° CPU")
    print("‚ö†Ô∏è  Performance ser√° muito mais lenta!")
    print("   Lat√™ncia esperada: 3-30 segundos (vs 0.5-0.8s com GPU)")

print("\n" + "="*70)

