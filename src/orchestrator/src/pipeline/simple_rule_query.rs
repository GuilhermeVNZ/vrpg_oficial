//! Simple Rule Query - M3.2
//! Handles simple rule queries using Vectorizer + 1.5B (not 14B)

use crate::error::Result;
use crate::pipeline::PipelineState;
use tracing::info;

/// Result of simple rule query
#[derive(Debug, Clone)]
pub struct SimpleRuleQueryResult {
    /// Human-like answer generated by 1.5B
    pub answer: String,
    /// Whether 1.5B was used for conversion
    pub used_1_5b: bool,
    /// Whether 14B was used (should always be false for simple rule queries)
    pub used_14b: bool,
    /// Latency in milliseconds
    pub latency_ms: u64,
}

/// Answer simple rule query using Vectorizer + 1.5B
pub async fn answer_simple_rule_query(
    _state: &PipelineState,
    query: &str,
    vectorizer_results: &[String],
) -> Result<SimpleRuleQueryResult> {
    let start_time = std::time::Instant::now();
    info!("Answering simple rule query: {}", query);

    // If no vectorizer results, return a default response
    if vectorizer_results.is_empty() {
        return Ok(SimpleRuleQueryResult {
            answer: "Não foi possível encontrar essa regra no sistema.".to_string(),
            used_1_5b: false,
            used_14b: false,
            latency_ms: start_time.elapsed().as_millis() as u64,
        });
    }

    // Combine vectorizer results into context
    let rule_text = vectorizer_results.join(". ");

    // TODO: Call 1.5B to convert rule text into human-like response
    // For now, return a mock response that mimics what 1.5B would generate
    let answer = format_rule_answer(query, &rule_text);

    let latency = start_time.elapsed();
    info!("Simple rule query answered in {:?}", latency);

    Ok(SimpleRuleQueryResult {
        answer,
        used_1_5b: true, // In real implementation, this would be true if 1.5B was called
        used_14b: false, // 14B should never be called for simple rule queries
        latency_ms: latency.as_millis() as u64,
    })
}

/// Format rule answer in human-like way (mock of 1.5B conversion)
fn format_rule_answer(query: &str, rule_text: &str) -> String {
    // Simple formatting - in real implementation, 1.5B would do this
    let query_lower = query.to_lowercase();

    if query_lower.contains("stealth") && query_lower.contains("destreza") {
        "Sim, Stealth usa Destreza.".to_string()
    } else if query_lower.contains("investigation") && query_lower.contains("inteligência") {
        "Sim, Investigation é baseada em Inteligência.".to_string()
    } else if query_lower.contains("acrobatics") || query_lower.contains("acrobacia") {
        "Acrobatics usa Destreza.".to_string()
    } else {
        // Default: extract key information from rule_text
        format!("Baseado nas regras: {}.", rule_text)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_answer_simple_rule_query_basic() {
        let state = PipelineState::new();
        let query = "Stealth usa Destreza?";
        let vectorizer_results = vec!["Stealth is Dexterity-based.".to_string()];

        let result = answer_simple_rule_query(&state, query, &vectorizer_results)
            .await
            .unwrap();

        assert!(!result.answer.is_empty());
        assert!(result.used_1_5b);
        assert!(!result.used_14b);
    }

    #[tokio::test]
    async fn test_format_rule_answer() {
        let answer = format_rule_answer("Stealth usa Destreza?", "Stealth is Dexterity-based.");
        assert!(answer.contains("Destreza"));
    }
}


